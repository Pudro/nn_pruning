{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Efficient Machine Learning - Fine-grained and channel pruning\nThis notebook concerns the concept of neural network pruning. The concepts of fine-grained and channel pruning are implemented and tested. The performance improvements and differences and tradeoffs between these pruning approaches are compared","metadata":{}},{"cell_type":"markdown","source":"## Model and setup\nWe will conduct the experiments on VGG16. The model is quite outdated by today standards, however, it is easily dissectable and there are verious pretrained variants available. This makes it suitable for the purpose of this notebook.","metadata":{}},{"cell_type":"code","source":"%pip install torchprofile","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:05:47.852260Z","iopub.execute_input":"2024-05-06T09:05:47.852614Z","iopub.status.idle":"2024-05-06T09:06:01.477295Z","shell.execute_reply.started":"2024-05-06T09:05:47.852575Z","shell.execute_reply":"2024-05-06T09:06:01.476147Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchprofile\n  Downloading torchprofile-0.0.4-py3-none-any.whl.metadata (303 bytes)\nRequirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.10/site-packages (from torchprofile) (1.26.4)\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.10/site-packages (from torchprofile) (2.1.2)\nRequirement already satisfied: torchvision>=0.4 in /opt/conda/lib/python3.10/site-packages (from torchprofile) (0.16.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.4->torchprofile) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.4->torchprofile) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4->torchprofile) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\nDownloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\nInstalling collected packages: torchprofile\nSuccessfully installed torchprofile-0.0.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import copy\nimport math\nimport random\nimport time\nfrom collections import OrderedDict, defaultdict\nfrom typing import Union, List\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.optim import *\nfrom torch.optim.lr_scheduler import *\nfrom torch.utils.data import DataLoader\nfrom torchprofile import profile_macs\nfrom torchvision.datasets import *\nfrom torchvision.transforms import *\nfrom torchvision.models import vgg16\nfrom tqdm.auto import tqdm\n\n# Ensure CUDA support\nassert torch.cuda.is_available(), \"The runtime has no CUDA support\"","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:06:01.479754Z","iopub.execute_input":"2024-05-06T09:06:01.480587Z","iopub.status.idle":"2024-05-06T09:06:06.994217Z","shell.execute_reply.started":"2024-05-06T09:06:01.480547Z","shell.execute_reply":"2024-05-06T09:06:06.993348Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# setting seeds for reproducability\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:06:06.995492Z","iopub.execute_input":"2024-05-06T09:06:06.996132Z","iopub.status.idle":"2024-05-06T09:06:07.007553Z","shell.execute_reply.started":"2024-05-06T09:06:06.996102Z","shell.execute_reply":"2024-05-06T09:06:07.006593Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7c0a0ec63410>"},"metadata":{}}]},{"cell_type":"markdown","source":"The model architecture is the same as vgg11_bn in torchvision - this enables us to use the weights pretrained on imagenet_1k. This class definition is used to add explicit layer names to the model.","metadata":{}},{"cell_type":"code","source":"class VGG(nn.Module):\n#   ARCH = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n  ARCH =  [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"]\n\n  def __init__(self) -> None:\n    super().__init__()\n\n    layers = []\n    counts = defaultdict(int)\n\n    def add(name: str, layer: nn.Module) -> None:\n      layers.append((f\"{name}{counts[name]}\", layer))\n      counts[name] += 1\n\n    in_channels = 3\n    for x in self.ARCH:\n      if x != 'M':\n        # conv-bn-relu\n        add(\"conv\", nn.Conv2d(in_channels, x, 3, padding=1, bias=False))\n        add(\"bn\", nn.BatchNorm2d(x))\n        add(\"relu\", nn.ReLU(True))\n        in_channels = x\n      else:\n        # maxpool\n        add(\"pool\", nn.MaxPool2d(2))\n\n    self.backbone = nn.Sequential(OrderedDict(layers))\n    self.classifier = nn.Linear(512, 10)\n\n  def forward(self, x: torch.Tensor) -> torch.Tensor:\n    # backbone: [N, 3, 32, 32] => [N, 512, 2, 2]\n    x = self.backbone(x)\n\n    # avgpool: [N, 512, 2, 2] => [N, 512]\n    x = x.mean([2, 3])\n\n    # classifier: [N, 512] => [N, 10]\n    x = self.classifier(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:06:07.009521Z","iopub.execute_input":"2024-05-06T09:06:07.009816Z","iopub.status.idle":"2024-05-06T09:06:07.020019Z","shell.execute_reply.started":"2024-05-06T09:06:07.009793Z","shell.execute_reply":"2024-05-06T09:06:07.019045Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model = VGG().cuda()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:06:07.021224Z","iopub.execute_input":"2024-05-06T09:06:07.021539Z","iopub.status.idle":"2024-05-06T09:06:07.321064Z","shell.execute_reply.started":"2024-05-06T09:06:07.021508Z","shell.execute_reply":"2024-05-06T09:06:07.320231Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:06:07.322244Z","iopub.execute_input":"2024-05-06T09:06:07.322864Z","iopub.status.idle":"2024-05-06T09:06:07.329630Z","shell.execute_reply.started":"2024-05-06T09:06:07.322830Z","shell.execute_reply":"2024-05-06T09:06:07.328656Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (backbone): Sequential(\n    (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu0): ReLU(inplace=True)\n    (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu1): ReLU(inplace=True)\n    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu3): ReLU(inplace=True)\n    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu4): ReLU(inplace=True)\n    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu5): ReLU(inplace=True)\n    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (conv6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu6): ReLU(inplace=True)\n    (conv7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu7): ReLU(inplace=True)\n    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    print(name, param.size())","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:06:07.330632Z","iopub.execute_input":"2024-05-06T09:06:07.330914Z","iopub.status.idle":"2024-05-06T09:06:07.338960Z","shell.execute_reply.started":"2024-05-06T09:06:07.330870Z","shell.execute_reply":"2024-05-06T09:06:07.338051Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"backbone.conv0.weight torch.Size([64, 3, 3, 3])\nbackbone.bn0.weight torch.Size([64])\nbackbone.bn0.bias torch.Size([64])\nbackbone.conv1.weight torch.Size([128, 64, 3, 3])\nbackbone.bn1.weight torch.Size([128])\nbackbone.bn1.bias torch.Size([128])\nbackbone.conv2.weight torch.Size([256, 128, 3, 3])\nbackbone.bn2.weight torch.Size([256])\nbackbone.bn2.bias torch.Size([256])\nbackbone.conv3.weight torch.Size([256, 256, 3, 3])\nbackbone.bn3.weight torch.Size([256])\nbackbone.bn3.bias torch.Size([256])\nbackbone.conv4.weight torch.Size([512, 256, 3, 3])\nbackbone.bn4.weight torch.Size([512])\nbackbone.bn4.bias torch.Size([512])\nbackbone.conv5.weight torch.Size([512, 512, 3, 3])\nbackbone.bn5.weight torch.Size([512])\nbackbone.bn5.bias torch.Size([512])\nbackbone.conv6.weight torch.Size([512, 512, 3, 3])\nbackbone.bn6.weight torch.Size([512])\nbackbone.bn6.bias torch.Size([512])\nbackbone.conv7.weight torch.Size([512, 512, 3, 3])\nbackbone.bn7.weight torch.Size([512])\nbackbone.bn7.bias torch.Size([512])\nclassifier.weight torch.Size([10, 512])\nclassifier.bias torch.Size([10])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Load the pretrained model and transfer the weights.","metadata":{}},{"cell_type":"code","source":"from torchvision.models import vgg11_bn\ntorch_vgg = vgg11_bn(pretrained=True)\nstate_dict = torch_vgg.state_dict()\nmodel.load_state_dict(state_dict)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:06:07.340047Z","iopub.execute_input":"2024-05-06T09:06:07.340330Z","iopub.status.idle":"2024-05-06T09:06:13.431195Z","shell.execute_reply.started":"2024-05-06T09:06:07.340307Z","shell.execute_reply":"2024-05-06T09:06:13.429506Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_BN_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /root/.cache/torch/hub/checkpoints/vgg11_bn-6002323d.pth\n100%|██████████| 507M/507M [00:03<00:00, 159MB/s]  \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m torch_vgg \u001b[38;5;241m=\u001b[39m vgg11_bn(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch_vgg\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VGG:\n\tMissing key(s) in state_dict: \"backbone.conv0.weight\", \"backbone.bn0.weight\", \"backbone.bn0.bias\", \"backbone.bn0.running_mean\", \"backbone.bn0.running_var\", \"backbone.conv1.weight\", \"backbone.bn1.weight\", \"backbone.bn1.bias\", \"backbone.bn1.running_mean\", \"backbone.bn1.running_var\", \"backbone.conv2.weight\", \"backbone.bn2.weight\", \"backbone.bn2.bias\", \"backbone.bn2.running_mean\", \"backbone.bn2.running_var\", \"backbone.conv3.weight\", \"backbone.bn3.weight\", \"backbone.bn3.bias\", \"backbone.bn3.running_mean\", \"backbone.bn3.running_var\", \"backbone.conv4.weight\", \"backbone.bn4.weight\", \"backbone.bn4.bias\", \"backbone.bn4.running_mean\", \"backbone.bn4.running_var\", \"backbone.conv5.weight\", \"backbone.bn5.weight\", \"backbone.bn5.bias\", \"backbone.bn5.running_mean\", \"backbone.bn5.running_var\", \"backbone.conv6.weight\", \"backbone.bn6.weight\", \"backbone.bn6.bias\", \"backbone.bn6.running_mean\", \"backbone.bn6.running_var\", \"backbone.conv7.weight\", \"backbone.bn7.weight\", \"backbone.bn7.bias\", \"backbone.bn7.running_mean\", \"backbone.bn7.running_var\", \"classifier.weight\", \"classifier.bias\". \n\tUnexpected key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.1.weight\", \"features.1.bias\", \"features.1.running_mean\", \"features.1.running_var\", \"features.1.num_batches_tracked\", \"features.4.weight\", \"features.4.bias\", \"features.5.weight\", \"features.5.bias\", \"features.5.running_mean\", \"features.5.running_var\", \"features.5.num_batches_tracked\", \"features.8.weight\", \"features.8.bias\", \"features.9.weight\", \"features.9.bias\", \"features.9.running_mean\", \"features.9.running_var\", \"features.9.num_batches_tracked\", \"features.11.weight\", \"features.11.bias\", \"features.12.weight\", \"features.12.bias\", \"features.12.running_mean\", \"features.12.running_var\", \"features.12.num_batches_tracked\", \"features.15.weight\", \"features.15.bias\", \"features.16.weight\", \"features.16.bias\", \"features.16.running_mean\", \"features.16.running_var\", \"features.16.num_batches_tracked\", \"features.18.weight\", \"features.18.bias\", \"features.19.weight\", \"features.19.bias\", \"features.19.running_mean\", \"features.19.running_var\", \"features.19.num_batches_tracked\", \"features.22.weight\", \"features.22.bias\", \"features.23.weight\", \"features.23.bias\", \"features.23.running_mean\", \"features.23.running_var\", \"features.23.num_batches_tracked\", \"features.25.weight\", \"features.25.bias\", \"features.26.weight\", \"features.26.bias\", \"features.26.running_mean\", \"features.26.running_var\", \"features.26.num_batches_tracked\", \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\", \"classifier.6.weight\", \"classifier.6.bias\". "],"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for VGG:\n\tMissing key(s) in state_dict: \"backbone.conv0.weight\", \"backbone.bn0.weight\", \"backbone.bn0.bias\", \"backbone.bn0.running_mean\", \"backbone.bn0.running_var\", \"backbone.conv1.weight\", \"backbone.bn1.weight\", \"backbone.bn1.bias\", \"backbone.bn1.running_mean\", \"backbone.bn1.running_var\", \"backbone.conv2.weight\", \"backbone.bn2.weight\", \"backbone.bn2.bias\", \"backbone.bn2.running_mean\", \"backbone.bn2.running_var\", \"backbone.conv3.weight\", \"backbone.bn3.weight\", \"backbone.bn3.bias\", \"backbone.bn3.running_mean\", \"backbone.bn3.running_var\", \"backbone.conv4.weight\", \"backbone.bn4.weight\", \"backbone.bn4.bias\", \"backbone.bn4.running_mean\", \"backbone.bn4.running_var\", \"backbone.conv5.weight\", \"backbone.bn5.weight\", \"backbone.bn5.bias\", \"backbone.bn5.running_mean\", \"backbone.bn5.running_var\", \"backbone.conv6.weight\", \"backbone.bn6.weight\", \"backbone.bn6.bias\", \"backbone.bn6.running_mean\", \"backbone.bn6.running_var\", \"backbone.conv7.weight\", \"backbone.bn7.weight\", \"backbone.bn7.bias\", \"backbone.bn7.running_mean\", \"backbone.bn7.running_var\", \"classifier.weight\", \"classifier.bias\". \n\tUnexpected key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.1.weight\", \"features.1.bias\", \"features.1.running_mean\", \"features.1.running_var\", \"features.1.num_batches_tracked\", \"features.4.weight\", \"features.4.bias\", \"features.5.weight\", \"features.5.bias\", \"features.5.running_mean\", \"features.5.running_var\", \"features.5.num_batches_tracked\", \"features.8.weight\", \"features.8.bias\", \"features.9.weight\", \"features.9.bias\", \"features.9.running_mean\", \"features.9.running_var\", \"features.9.num_batches_tracked\", \"features.11.weight\", \"features.11.bias\", \"features.12.weight\", \"features.12.bias\", \"features.12.running_mean\", \"features.12.running_var\", \"features.12.num_batches_tracked\", \"features.15.weight\", \"features.15.bias\", \"features.16.weight\", \"features.16.bias\", \"features.16.running_mean\", \"features.16.running_var\", \"features.16.num_batches_tracked\", \"features.18.weight\", \"features.18.bias\", \"features.19.weight\", \"features.19.bias\", \"features.19.running_mean\", \"features.19.running_var\", \"features.19.num_batches_tracked\", \"features.22.weight\", \"features.22.bias\", \"features.23.weight\", \"features.23.bias\", \"features.23.running_mean\", \"features.23.running_var\", \"features.23.num_batches_tracked\", \"features.25.weight\", \"features.25.bias\", \"features.26.weight\", \"features.26.bias\", \"features.26.running_mean\", \"features.26.running_var\", \"features.26.num_batches_tracked\", \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\", \"classifier.6.weight\", \"classifier.6.bias\". ","output_type":"error"}]},{"cell_type":"code","source":"VGG11_BN_Weights.__dict__","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:06:13.432118Z","iopub.status.idle":"2024-05-06T09:06:13.432487Z","shell.execute_reply.started":"2024-05-06T09:06:13.432300Z","shell.execute_reply":"2024-05-06T09:06:13.432318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_vgg","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:06:13.433305Z","iopub.status.idle":"2024-05-06T09:06:13.433747Z","shell.execute_reply.started":"2024-05-06T09:06:13.433533Z","shell.execute_reply":"2024-05-06T09:06:13.433551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for module in torch_vgg.modules():\n    print(module)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:06:13.435776Z","iopub.status.idle":"2024-05-06T09:06:13.436123Z","shell.execute_reply.started":"2024-05-06T09:06:13.435956Z","shell.execute_reply":"2024-05-06T09:06:13.435969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_vgg","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:07:54.141463Z","iopub.execute_input":"2024-05-06T09:07:54.141853Z","iopub.status.idle":"2024-05-06T09:07:54.149513Z","shell.execute_reply.started":"2024-05-06T09:07:54.141810Z","shell.execute_reply":"2024-05-06T09:07:54.148557Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU(inplace=True)\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU(inplace=True)\n    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (13): ReLU(inplace=True)\n    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (17): ReLU(inplace=True)\n    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (20): ReLU(inplace=True)\n    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (24): ReLU(inplace=True)\n    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (27): ReLU(inplace=True)\n    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for module in torch_vgg.named_modules():\n    print(module)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T09:09:36.924524Z","iopub.execute_input":"2024-05-06T09:09:36.925156Z","iopub.status.idle":"2024-05-06T09:09:36.930998Z","shell.execute_reply.started":"2024-05-06T09:09:36.925124Z","shell.execute_reply":"2024-05-06T09:09:36.930041Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"('', VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU(inplace=True)\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU(inplace=True)\n    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (13): ReLU(inplace=True)\n    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (17): ReLU(inplace=True)\n    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (20): ReLU(inplace=True)\n    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (24): ReLU(inplace=True)\n    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (27): ReLU(inplace=True)\n    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n))\n('features', Sequential(\n  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (6): ReLU(inplace=True)\n  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (10): ReLU(inplace=True)\n  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (13): ReLU(inplace=True)\n  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (17): ReLU(inplace=True)\n  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (20): ReLU(inplace=True)\n  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (24): ReLU(inplace=True)\n  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (27): ReLU(inplace=True)\n  (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n))\n('features.0', Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('features.1', BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n('features.2', ReLU(inplace=True))\n('features.3', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('features.4', Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('features.5', BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n('features.6', ReLU(inplace=True))\n('features.7', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('features.8', Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('features.9', BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n('features.10', ReLU(inplace=True))\n('features.11', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('features.12', BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n('features.13', ReLU(inplace=True))\n('features.14', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('features.15', Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('features.16', BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n('features.17', ReLU(inplace=True))\n('features.18', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('features.19', BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n('features.20', ReLU(inplace=True))\n('features.21', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('features.22', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('features.23', BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n('features.24', ReLU(inplace=True))\n('features.25', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n('features.26', BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n('features.27', ReLU(inplace=True))\n('features.28', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('avgpool', AdaptiveAvgPool2d(output_size=(7, 7)))\n('classifier', Sequential(\n  (0): Linear(in_features=25088, out_features=4096, bias=True)\n  (1): ReLU(inplace=True)\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=4096, out_features=4096, bias=True)\n  (4): ReLU(inplace=True)\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=4096, out_features=1000, bias=True)\n))\n('classifier.0', Linear(in_features=25088, out_features=4096, bias=True))\n('classifier.1', ReLU(inplace=True))\n('classifier.2', Dropout(p=0.5, inplace=False))\n('classifier.3', Linear(in_features=4096, out_features=4096, bias=True))\n('classifier.4', ReLU(inplace=True))\n('classifier.5', Dropout(p=0.5, inplace=False))\n('classifier.6', Linear(in_features=4096, out_features=1000, bias=True))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}