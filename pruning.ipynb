{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Efficient Machine Learning - Fine-grained and channel pruning\n","This notebook concerns the concept of neural network pruning. The concepts of fine-grained and channel pruning are implemented and tested. The performance improvements and differences and tradeoffs between these pruning approaches are compared"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Model and setup\n","We will conduct the experiments on VGG16. The model is quite outdated by today standards, however, it is easily dissectable and there are verious pretrained variants available. This makes it suitable for the purpose of this notebook."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:05:47.852614Z","iopub.status.busy":"2024-05-06T09:05:47.852260Z","iopub.status.idle":"2024-05-06T09:06:01.477295Z","shell.execute_reply":"2024-05-06T09:06:01.476147Z","shell.execute_reply.started":"2024-05-06T09:05:47.852575Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchprofile in ./.venv/lib/python3.11/site-packages (0.0.4)\n","Requirement already satisfied: numpy>=1.14 in ./.venv/lib/python3.11/site-packages (from torchprofile) (1.26.4)\n","Requirement already satisfied: torch>=1.4 in ./.venv/lib/python3.11/site-packages (from torchprofile) (2.3.0)\n","Requirement already satisfied: torchvision>=0.4 in ./.venv/lib/python3.11/site-packages (from torchprofile) (0.18.0)\n","Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (4.11.0)\n","Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (1.12)\n","Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (3.3)\n","Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (3.1.4)\n","Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (2024.3.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in ./.venv/lib/python3.11/site-packages (from torch>=1.4->torchprofile) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->torchprofile) (12.4.127)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.11/site-packages (from torchvision>=0.4->torchprofile) (10.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.4->torchprofile) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install torchprofile"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:06:01.480587Z","iopub.status.busy":"2024-05-06T09:06:01.479754Z","iopub.status.idle":"2024-05-06T09:06:06.994217Z","shell.execute_reply":"2024-05-06T09:06:06.993348Z","shell.execute_reply.started":"2024-05-06T09:06:01.480547Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ppst/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","/home/ppst/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n","  return torch._C._cuda_getDeviceCount() > 0\n"]},{"ename":"AssertionError","evalue":"The runtime has no CUDA support","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m     22\u001b[0m \u001b[39m# Ensure CUDA support\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available(), \u001b[39m\"\u001b[39m\u001b[39mThe runtime has no CUDA support\u001b[39m\u001b[39m\"\u001b[39m\n","\u001b[0;31mAssertionError\u001b[0m: The runtime has no CUDA support"]}],"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","import copy\n","import math\n","import random\n","import time\n","from collections import OrderedDict, defaultdict\n","from typing import Union, List\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.optim import *\n","from torch.optim.lr_scheduler import *\n","from torch.utils.data import DataLoader\n","from torchprofile import profile_macs\n","from torchvision.datasets import *\n","from torchvision.transforms import *\n","from torchvision.models import vgg16\n","from tqdm.auto import tqdm\n","\n","# Ensure CUDA support\n","assert torch.cuda.is_available(), \"The runtime has no CUDA support\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:06:06.996132Z","iopub.status.busy":"2024-05-06T09:06:06.995492Z","iopub.status.idle":"2024-05-06T09:06:07.007553Z","shell.execute_reply":"2024-05-06T09:06:07.006593Z","shell.execute_reply.started":"2024-05-06T09:06:06.996102Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x768c483451f0>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# setting seeds for reproducability\n","random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The model architecture is the same as vgg11_bn in torchvision - this enables us to use the weights pretrained on imagenet_1k. This class definition is used to add explicit layer names to the model.\n","\n","## Edit\n","This model class is no longer needed. We are changing the layer names in the pretrained pytorch model instead."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:06:07.009816Z","iopub.status.busy":"2024-05-06T09:06:07.009521Z","iopub.status.idle":"2024-05-06T09:06:07.020019Z","shell.execute_reply":"2024-05-06T09:06:07.019045Z","shell.execute_reply.started":"2024-05-06T09:06:07.009793Z"},"trusted":true},"outputs":[],"source":["class VGG(nn.Module):\n","  ARCH = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n","  # ARCH =  [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"]\n","\n","  def __init__(self) -> None:\n","    super().__init__()\n","\n","    layers = []\n","    counts = defaultdict(int)\n","\n","    def add(name: str, layer: nn.Module) -> None:\n","      layers.append((f\"{name}{counts[name]}\", layer))\n","      counts[name] += 1\n","\n","    in_channels = 3\n","    for x in self.ARCH:\n","      if x != 'M':\n","        # conv-bn-relu\n","        add(\"conv\", nn.Conv2d(in_channels, x, 3, padding=1, bias=False))\n","        add(\"bn\", nn.BatchNorm2d(x))\n","        add(\"relu\", nn.ReLU(True))\n","        in_channels = x\n","      else:\n","        # maxpool\n","        add(\"pool\", nn.MaxPool2d(2))\n","\n","    self.backbone = nn.Sequential(OrderedDict(layers))\n","    self.classifier = nn.Linear(512, 10)\n","\n","  def forward(self, x: torch.Tensor) -> torch.Tensor:\n","    # backbone: [N, 3, 32, 32] => [N, 512, 2, 2]\n","    x = self.backbone(x)\n","\n","    # avgpool: [N, 512, 2, 2] => [N, 512]\n","    x = x.mean([2, 3])\n","\n","    # classifier: [N, 512] => [N, 10]\n","    x = self.classifier(x)\n","    return x"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:06:07.021539Z","iopub.status.busy":"2024-05-06T09:06:07.021224Z","iopub.status.idle":"2024-05-06T09:06:07.321064Z","shell.execute_reply":"2024-05-06T09:06:07.320231Z","shell.execute_reply.started":"2024-05-06T09:06:07.021508Z"},"trusted":true},"outputs":[{"ename":"RuntimeError","evalue":"CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m VGG()\u001b[39m.\u001b[39;49mcuda()\n","File \u001b[0;32m~/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    899\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \n\u001b[1;32m    901\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n","File \u001b[0;32m~/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m~/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m~/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[39m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n","File \u001b[0;32m~/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    899\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \n\u001b[1;32m    901\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n","File \u001b[0;32m~/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    294\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."]}],"source":["model = VGG().cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:06:07.322864Z","iopub.status.busy":"2024-05-06T09:06:07.322244Z","iopub.status.idle":"2024-05-06T09:06:07.329630Z","shell.execute_reply":"2024-05-06T09:06:07.328656Z","shell.execute_reply.started":"2024-05-06T09:06:07.322830Z"},"trusted":true},"outputs":[{"data":{"text/plain":["VGG(\n","  (backbone): Sequential(\n","    (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu0): ReLU(inplace=True)\n","    (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu1): ReLU(inplace=True)\n","    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu2): ReLU(inplace=True)\n","    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu3): ReLU(inplace=True)\n","    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu4): ReLU(inplace=True)\n","    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu5): ReLU(inplace=True)\n","    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu6): ReLU(inplace=True)\n","    (conv7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu7): ReLU(inplace=True)\n","    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:06:07.330914Z","iopub.status.busy":"2024-05-06T09:06:07.330632Z","iopub.status.idle":"2024-05-06T09:06:07.338960Z","shell.execute_reply":"2024-05-06T09:06:07.338051Z","shell.execute_reply.started":"2024-05-06T09:06:07.330870Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mnamed_parameters():\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(name, param\u001b[39m.\u001b[39msize())\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["for name, param in model.named_parameters():\n","    print(name, param.size())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load the pretrained model and transfer the weights."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## pretrained model from pytroch"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:06:07.340330Z","iopub.status.busy":"2024-05-06T09:06:07.340047Z","iopub.status.idle":"2024-05-06T09:06:13.431195Z","shell.execute_reply":"2024-05-06T09:06:13.429506Z","shell.execute_reply.started":"2024-05-06T09:06:07.340307Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ppst/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/ppst/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_BN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU(inplace=True)\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU(inplace=True)\n","    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (13): ReLU(inplace=True)\n","    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (17): ReLU(inplace=True)\n","    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (20): ReLU(inplace=True)\n","    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (24): ReLU(inplace=True)\n","    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (27): ReLU(inplace=True)\n","    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"]}],"source":["from torchvision.models import vgg11_bn\n","model = vgg11_bn(pretrained=True)\n","\n","print(model)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Change layer names for further visualization"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["VGG(\n","  (features): Sequential(\n","    (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu0): ReLU(inplace=True)\n","    (maxpool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu1): ReLU(inplace=True)\n","    (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu2): ReLU(inplace=True)\n","    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu3): ReLU(inplace=True)\n","    (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu4): ReLU(inplace=True)\n","    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu5): ReLU(inplace=True)\n","    (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu6): ReLU(inplace=True)\n","    (conv7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu7): ReLU(inplace=True)\n","    (maxpool7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (linear0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (relu0): ReLU(inplace=True)\n","    (maxpool0): Dropout(p=0.5, inplace=False)\n","    (linear1): Linear(in_features=4096, out_features=4096, bias=True)\n","    (relu1): ReLU(inplace=True)\n","    (maxpool1): Dropout(p=0.5, inplace=False)\n","    (linear2): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"]}],"source":["class KV_Getter:\n","    def __init__(self):\n","        self.it = 0\n","\n","    def get_kv(self, k, v):\n","        if isinstance(v, torch.nn.modules.conv.Conv2d):\n","            return (f'conv{self.it}', v)\n","        elif isinstance(v, torch.nn.modules.batchnorm.BatchNorm2d):\n","            return (f'batchnorm{self.it}', v)\n","        elif isinstance(v, torch.nn.modules.activation.ReLU):\n","            self.it += 1\n","            return (f'relu{self.it-1}', v)\n","        elif isinstance(v, torch.nn.modules.pooling.MaxPool2d):\n","            return (f'maxpool{self.it-1}', v)\n","        else:\n","            return (k, v)\n","\n","    def get_kv_classifier(self, k, v):\n","        if isinstance(v, torch.nn.Linear):\n","            return (f'linear{self.it}', v)\n","        elif isinstance(v, torch.nn.modules.activation.ReLU):\n","            return (f'relu{self.it}', v)\n","        elif isinstance(v, torch.nn.Dropout):\n","            self.it += 1\n","            return (f'maxpool{self.it-1}', v)\n","        else:\n","            return (k, v)\n","            \n","kvg = KV_Getter()\n","new_od = OrderedDict([kvg.get_kv(k,v) for k, v in model._modules['features']._modules.items()])\n","\n","kvg = KV_Getter()\n","new_od_classifier = OrderedDict([kvg.get_kv_classifier(k,v) for k, v in model._modules['classifier']._modules.items()])\n","\n","        \n","model._modules['features']._modules = new_od\n","model._modules['classifier']._modules = new_od_classifier\n","\n","print(model)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["features.conv0.weight\n","features.conv0.bias\n","features.batchnorm0.weight\n","features.batchnorm0.bias\n","features.conv1.weight\n","features.conv1.bias\n","features.batchnorm1.weight\n","features.batchnorm1.bias\n","features.conv2.weight\n","features.conv2.bias\n","features.batchnorm2.weight\n","features.batchnorm2.bias\n","features.conv3.weight\n","features.conv3.bias\n","features.batchnorm3.weight\n","features.batchnorm3.bias\n","features.conv4.weight\n","features.conv4.bias\n","features.batchnorm4.weight\n","features.batchnorm4.bias\n","features.conv5.weight\n","features.conv5.bias\n","features.batchnorm5.weight\n","features.batchnorm5.bias\n","features.conv6.weight\n","features.conv6.bias\n","features.batchnorm6.weight\n","features.batchnorm6.bias\n","features.conv7.weight\n","features.conv7.bias\n","features.batchnorm7.weight\n","features.batchnorm7.bias\n","classifier.linear0.weight\n","classifier.linear0.bias\n","classifier.linear1.weight\n","classifier.linear1.bias\n","classifier.linear2.weight\n","classifier.linear2.bias\n"]}],"source":["for name, param in model.named_parameters():\n","    print(name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Utility function for training, inference, etc."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def train(\n","  model: nn.Module,\n","  dataloader: DataLoader,\n","  criterion: nn.Module,\n","  optimizer: Optimizer,\n","  scheduler: LambdaLR,\n","  callbacks = None\n",") -> None:\n","  model.train()\n","\n","  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n","    # Move the data from CPU to GPU\n","    inputs = inputs.cuda()\n","    targets = targets.cuda()\n","\n","    # Reset the gradients (from the last iteration)\n","    optimizer.zero_grad()\n","\n","    # Forward inference\n","    outputs = model(inputs)\n","    loss = criterion(outputs, targets)\n","\n","    # Backward propagation\n","    loss.backward()\n","\n","    # Update optimizer and LR scheduler\n","    optimizer.step()\n","    scheduler.step()\n","\n","    if callbacks is not None:\n","        for callback in callbacks:\n","            callback()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["@torch.inference_mode()\n","def evaluate(\n","  model: nn.Module,\n","  dataloader: DataLoader,\n","  verbose=True,\n",") -> float:\n","  model.eval()\n","\n","  num_samples = 0\n","  num_correct = 0\n","\n","  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False,\n","                              disable=not verbose):\n","    # Move the data from CPU to GPU\n","    inputs = inputs.cuda()\n","    targets = targets.cuda()\n","\n","    # Inference\n","    outputs = model(inputs)\n","\n","    # Convert logits to class indices\n","    outputs = outputs.argmax(dim=1)\n","\n","    # Update metrics\n","    num_samples += targets.size(0)\n","    num_correct += (outputs == targets).sum()\n","\n","  return (num_correct / num_samples * 100).item()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Helper Functions (Flops, Model Size calculation, etc.)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def get_model_macs(model, inputs) -> int:\n","    return profile_macs(model, inputs)\n","\n","\n","def get_sparsity(tensor: torch.Tensor) -> float:\n","    \"\"\"\n","    calculate the sparsity of the given tensor\n","        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n","    \"\"\"\n","    return 1 - float(tensor.count_nonzero()) / tensor.numel()\n","\n","\n","def get_model_sparsity(model: nn.Module) -> float:\n","    \"\"\"\n","    calculate the sparsity of the given model\n","        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n","    \"\"\"\n","    num_nonzeros, num_elements = 0, 0\n","    for param in model.parameters():\n","        num_nonzeros += param.count_nonzero()\n","        num_elements += param.numel()\n","    return 1 - float(num_nonzeros) / num_elements\n","\n","def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n","    \"\"\"\n","    calculate the total number of parameters of model\n","    :param count_nonzero_only: only count nonzero weights\n","    \"\"\"\n","    num_counted_elements = 0\n","    for param in model.parameters():\n","        if count_nonzero_only:\n","            num_counted_elements += param.count_nonzero()\n","        else:\n","            num_counted_elements += param.numel()\n","    return num_counted_elements\n","\n","\n","def get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n","    \"\"\"\n","    calculate the model size in bits\n","    :param data_width: #bits per element\n","    :param count_nonzero_only: only count nonzero weights\n","    \"\"\"\n","    return get_num_parameters(model, count_nonzero_only) * data_width\n","\n","Byte = 8\n","KiB = 1024 * Byte\n","MiB = 1024 * KiB\n","GiB = 1024 * MiB"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Define misc functions for verification."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def test_fine_grained_prune(\n","    test_tensor=torch.tensor([[-0.46, -0.40, 0.39, 0.19, 0.37],\n","                              [0.00, 0.40, 0.17, -0.15, 0.16],\n","                              [-0.20, -0.23, 0.36, 0.25, 0.03],\n","                              [0.24, 0.41, 0.07, 0.13, -0.15],\n","                              [0.48, -0.09, -0.36, 0.12, 0.45]]),\n","    test_mask=torch.tensor([[True, True, False, False, False],\n","                            [False, True, False, False, False],\n","                            [False, False, False, False, False],\n","                            [False, True, False, False, False],\n","                            [True, False, False, False, True]]),\n","    target_sparsity=0.75, target_nonzeros=None):\n","    def plot_matrix(tensor, ax, title):\n","        ax.imshow(tensor.cpu().numpy() == 0, vmin=0, vmax=1, cmap='tab20c')\n","        ax.set_title(title)\n","        ax.set_yticklabels([])\n","        ax.set_xticklabels([])\n","        for i in range(tensor.shape[1]):\n","            for j in range(tensor.shape[0]):\n","                text = ax.text(j, i, f'{tensor[i, j].item():.2f}',\n","                                ha=\"center\", va=\"center\", color=\"k\")\n","\n","    test_tensor = test_tensor.clone()\n","    fig, axes = plt.subplots(1,2, figsize=(6, 10))\n","    ax_left, ax_right = axes.ravel()\n","    plot_matrix(test_tensor, ax_left, 'dense tensor')\n","\n","    sparsity_before_pruning = get_sparsity(test_tensor)\n","    mask = fine_grained_prune(test_tensor, target_sparsity)\n","    sparsity_after_pruning = get_sparsity(test_tensor)\n","    sparsity_of_mask = get_sparsity(mask)\n","\n","    plot_matrix(test_tensor, ax_right, 'sparse tensor')\n","    fig.tight_layout()\n","    plt.show()\n","\n","    print('* Test fine_grained_prune()')\n","    print(f'    target sparsity: {target_sparsity:.2f}')\n","    print(f'        sparsity before pruning: {sparsity_before_pruning:.2f}')\n","    print(f'        sparsity after pruning: {sparsity_after_pruning:.2f}')\n","    print(f'        sparsity of pruning mask: {sparsity_of_mask:.2f}')\n","\n","    if target_nonzeros is None:\n","        if test_mask.equal(mask):\n","            print('* Test passed.')\n","        else:\n","            print('* Test failed.')\n","    else:\n","        if mask.count_nonzero() == target_nonzeros:\n","            print('* Test passed.')\n","        else:\n","            print('* Test failed.')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["%rm data -r"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz to data/imagenette/train/imagenette2-160.tgz\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████████████████████████████████████████████████████████| 99003388/99003388 [00:04<00:00, 22133940.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/imagenette/train/imagenette2-160.tgz to data/imagenette/train\n","Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz to data/imagenette/val/imagenette2-160.tgz\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████████████████████████████████████████████████████████| 99003388/99003388 [00:04<00:00, 23146250.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/imagenette/val/imagenette2-160.tgz to data/imagenette/val\n"]}],"source":["image_size = 160\n","transforms = {\n","    \"train\": Compose([\n","        RandomCrop(image_size, padding=4),\n","        RandomHorizontalFlip(),\n","        ToTensor(),\n","    ]),\n","    \"val\": Compose([\n","      RandomCrop(image_size, padding=4),\n","      ToTensor()\n","    ])\n","}\n","dataset = {}\n","for split in [\"train\", \"val\"]:\n","  dataset[split] = Imagenette(\n","    root=f\"data/imagenette/{split}\",\n","    split=split,\n","    size='160px',\n","    download=True,\n","    transform=transforms[split],\n","  )\n","dataloader = {}\n","for split in ['train', 'val']:\n","  dataloader[split] = DataLoader(\n","    dataset[split],\n","    batch_size=512,\n","    shuffle=(split == 'train'),\n","    num_workers=0,\n","    pin_memory=True,\n","  )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Accuracy and Model Size of Dense Model"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                                                    \r"]},{"ename":"RuntimeError","evalue":"CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dense_model_accuracy \u001b[39m=\u001b[39m evaluate(model, dataloader[\u001b[39m'\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m dense_model_size \u001b[39m=\u001b[39m get_model_size(model)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdense model has accuracy=\u001b[39m\u001b[39m{\u001b[39;00mdense_model_accuracy\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","Cell \u001b[0;32mIn[10], line 15\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, verbose)\u001b[0m\n\u001b[1;32m     10\u001b[0m num_correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m tqdm(dataloader, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m                             disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m verbose):\n\u001b[1;32m     14\u001b[0m   \u001b[39m# Move the data from CPU to GPU\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m   inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m     16\u001b[0m   targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     18\u001b[0m   \u001b[39m# Inference\u001b[39;00m\n","File \u001b[0;32m~/Documents/agh/nn_pruning/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    294\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."]}],"source":["dense_model_accuracy = evaluate(model, dataloader['val'])\n","dense_model_size = get_model_size(model)\n","print(f\"dense model has accuracy={dense_model_accuracy:.2f}%\")\n","print(f\"dense model has size={dense_model_size/MiB:.2f} MiB\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["False"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"nn_pruning","language":"python","name":"nn_pruning"}},"nbformat":4,"nbformat_minor":4}
